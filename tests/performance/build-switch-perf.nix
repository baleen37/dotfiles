{ pkgs, flake ? null, src }:
let
  testHelpers = import ../lib/test-helpers.nix { inherit pkgs; };
  buildSwitchScript = "${src}/apps/aarch64-darwin/build-switch";
  buildSwitchCommon = "${src}/scripts/build-switch-common.sh";

  # Performance test thresholds (in seconds)
  thresholds = {
    maxEvaluationTime = 30;    # Target: 30ì´ˆ ì´í•˜ (í˜„ì¬ 63ì´ˆì—ì„œ 50% ê°œì„ )
    maxTotalTime = 60;         # Target: ì „ì²´ 60ì´ˆ ì´í•˜
    minCacheEfficiency = 20;   # Target: ìºì‹œ ì‚¬ìš© ì‹œ ìµœì†Œ 20% ì„±ëŠ¥ í–¥ìƒ
  };
in
pkgs.runCommand "build-switch-performance-test"
{
  buildInputs = with pkgs; [ bash coreutils nix time gnugrep findutils bc ];
} ''
  ${testHelpers.setupTestEnv}

  ${testHelpers.testSection "Build-Switch Performance Tests (TDD Cycle 1.1)"}

  # Test 1: í˜„ì¬ í‰ê°€ ì„±ëŠ¥ ì¸¡ì • (Baseline)
  ${testHelpers.testSubsection "Baseline Performance Measurement"}

  echo "ğŸ“Š Measuring current build evaluation performance..."

  # Dry-runìœ¼ë¡œ í‰ê°€ ì‹œê°„ë§Œ ì¸¡ì • (ë” í˜„ì‹¤ì ì¸ íƒ€ì„ì•„ì›ƒ)
  BASELINE_START=$(date +%s%N)
  if timeout 120 nix --extra-experimental-features 'nix-command flakes' build \
    --dry-run --no-warn-dirty .#darwinConfigurations.aarch64-darwin.system \
    --cores 1 --max-jobs 1 >/dev/null 2>&1; then
    BASELINE_END=$(date +%s%N)
    BASELINE_DURATION=$(( (BASELINE_END - BASELINE_START) / 1000000000 ))
    echo "âœ… Baseline evaluation time: ''${BASELINE_DURATION}s"
  else
    echo "âš ï¸ Baseline measurement timed out (>120s) - using simplified test"
    # ê°„ë‹¨í•œ flake checkìœ¼ë¡œ ëŒ€ì²´
    SIMPLE_START=$(date +%s%N)
    if timeout 60 nix flake check --impure --dry-run >/dev/null 2>&1; then
      SIMPLE_END=$(date +%s%N)
      BASELINE_DURATION=$(( (SIMPLE_END - SIMPLE_START) / 1000000000 ))
      echo "âœ… Simplified evaluation time: ''${BASELINE_DURATION}s"
    else
      BASELINE_DURATION=999
      echo "âŒ Even simplified measurement failed"
    fi
  fi

  # Test 2: í‰ê°€ ìºì‹œ ìµœì í™” í™•ì¸ (Green phaseì—ì„œëŠ” í†µê³¼ ì˜ˆìƒ)
  ${testHelpers.testSubsection "Eval Cache Optimization Check"}

  echo "ğŸ” Checking for eval-cache optimization implementation..."

  # build-logic.shì— --eval-cache í”Œë˜ê·¸ê°€ ìˆëŠ”ì§€ í™•ì¸
  if grep -q "eval-cache" "${src}/scripts/lib/build-logic.sh" 2>/dev/null; then
    echo "âœ… SUCCESS: eval-cache flag found in build script (Green phase success!)"
    EVAL_CACHE_IMPLEMENTED=true
  else
    echo "âŒ MISSING: eval-cache flag not found (Red phase - needs implementation)"
    EVAL_CACHE_IMPLEMENTED=false
  fi

  # ì„±ëŠ¥ ê¸°ì¤€ì¹˜ í™•ì¸
  if [ "$BASELINE_DURATION" -le "${toString thresholds.maxEvaluationTime}" ]; then
    echo "âœ… SUCCESS: Evaluation time (''${BASELINE_DURATION}s) meets target (${toString thresholds.maxEvaluationTime}s)"
    PERFORMANCE_TARGET_MET=true
  else
    echo "âš ï¸ WARNING: Evaluation time (''${BASELINE_DURATION}s) still exceeds target (${toString thresholds.maxEvaluationTime}s)"
    echo "Note: This may be due to test environment limitations or need additional optimizations"
    PERFORMANCE_TARGET_MET=false
  fi

  # Test 3: ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™” ë¶€ì¬ í™•ì¸ (ì‹¤íŒ¨ ì˜ˆìƒ)
  ${testHelpers.testSubsection "Parallel Processing Optimization Check (Expected to Fail)"}

  echo "ğŸ” Checking for CPU-optimized parallel processing..."

  # CPU ì½”ì–´ ìˆ˜ í™•ì¸
  if command -v nproc >/dev/null 2>&1; then
    AVAILABLE_CORES=$(nproc)
  elif command -v sysctl >/dev/null 2>&1; then
    AVAILABLE_CORES=$(sysctl -n hw.ncpu)
  else
    AVAILABLE_CORES=4
  fi

  echo "Available CPU cores: $AVAILABLE_CORES"

  # í˜„ì¬ ê³ ì •ëœ 8ì½”ì–´ ì œí•œì´ ìˆëŠ”ì§€ í™•ì¸
  if grep -q "CORES.*8" "${src}/scripts/lib/performance.sh" 2>/dev/null; then
    echo "âœ… EXPECTED: Fixed 8-core limit found (needs optimization)"
  else
    echo "âŒ UNEXPECTED: No fixed core limit found"
  fi

  # Test 4: ì¡°ê±´ë¶€ í‰ê°€ ìµœì í™” ë¶€ì¬ í™•ì¸ (ì‹¤íŒ¨ ì˜ˆìƒ)
  ${testHelpers.testSubsection "Conditional Evaluation Check (Expected to Fail)"}

  echo "ğŸ” Checking for platform-specific evaluation optimization..."

  # ëª¨ë“  ì•„í‚¤í…ì²˜ë¥¼ í‰ê°€í•˜ëŠ”ì§€ í™•ì¸
  EVALUATION_LOG=$(mktemp)
  timeout 120 nix --extra-experimental-features 'nix-command flakes' build \
    --dry-run --no-warn-dirty .#darwinConfigurations.aarch64-darwin.system \
    --show-trace 2>"$EVALUATION_LOG" >/dev/null || true

  # ë¶ˆí•„ìš”í•œ ì•„í‚¤í…ì²˜ í‰ê°€ ì—¬ë¶€ í™•ì¸
  if grep -q "x86_64\|linux" "$EVALUATION_LOG" 2>/dev/null; then
    echo "âœ… EXPECTED: Cross-platform evaluation detected (needs optimization)"
  else
    echo "âŒ Platform-specific evaluation check inconclusive"
  fi

  rm -f "$EVALUATION_LOG"

  # Test 5: ì„±ëŠ¥ ì¸¡ì • ê¸°ë°˜ ìµœì í™” í™•ì¸
  ${testHelpers.testSubsection "Performance Measurement Infrastructure"}

  echo "ğŸ” Checking for detailed performance measurement capabilities..."

  # ì„¸ë¶€ ì„±ëŠ¥ ì¸¡ì • í•¨ìˆ˜ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
  if grep -q "perf_start_phase.*build" "${src}/scripts/lib/performance.sh" 2>/dev/null; then
    echo "âœ… Basic performance measurement found"
  else
    echo "âŒ No detailed performance measurement found"
  fi

  # í‰ê°€ ë‹¨ê³„ë³„ ì¸¡ì • ë¶€ì¬ í™•ì¸ (ê°œì„  í•„ìš”)
  if grep -q "perf.*eval" "${src}/scripts/lib/performance.sh" 2>/dev/null; then
    echo "âŒ UNEXPECTED: Evaluation phase measurement already exists"
  else
    echo "âœ… EXPECTED: No evaluation phase measurement (needs implementation)"
  fi

  # Test Results Summary
  echo ""
  echo "ğŸ” Performance Test Summary (TDD Cycle 1.1):"
  echo "  ğŸ“Š Baseline evaluation time: ''${BASELINE_DURATION}s (target: ${toString thresholds.maxEvaluationTime}s)"
  echo "  ğŸ¯ Performance target: $([ "$PERFORMANCE_TARGET_MET" = "true" ] && echo "âœ… MET" || echo "âš ï¸ NEEDS MORE WORK")"
  echo "  ğŸš€ Eval cache optimization: $([ "$EVAL_CACHE_IMPLEMENTED" = "true" ] && echo "âœ… IMPLEMENTED" || echo "âŒ MISSING")"
  echo "  âš™ï¸ Dynamic core detection: NEEDS IMPLEMENTATION (next cycle)"
  echo "  ğŸ¯ Platform-specific evaluation: NEEDS IMPLEMENTATION (next cycle)"
  echo "  ğŸ“Š Detailed perf measurement: PARTIAL (next cycle)"
  echo ""

  # TDD Cycle 1.1 ê²°ê³¼ íŒì •
  if [ "$EVAL_CACHE_IMPLEMENTED" = "true" ]; then
    echo "âœ… TDD Cycle 1.1 Green phase: PASSED!"
    echo "âœ… Eval-cache optimization successfully implemented"
    echo "Next: Refactor phase - clean up and optimize code structure"
  else
    echo "âŒ TDD Cycle 1.1 Green phase: FAILED!"
    echo "âŒ Eval-cache optimization not found - implementation needed"
    exit 1
  fi

  # Create performance benchmark baseline file for Green phase
  echo "$BASELINE_DURATION" > /tmp/baseline_perf.txt
  echo "ğŸ“ Baseline performance recorded for Green phase comparison"

  ${testHelpers.cleanup}

  touch $out
''
